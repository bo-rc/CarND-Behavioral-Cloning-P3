{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cpu:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():  \n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29830\n",
      "8523\n",
      "4262\n",
      "/home/boliu1/Projects/CND/sim_data/data/IMG/center_2017_10_16_01_53_30_027.jpg\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "csv_filename = 'driving_log.csv'\n",
    "data_path = \"../sim_data/data/\"\n",
    "test_data_path = \"../sim_data/test_data/\"\n",
    "\n",
    "data_csv_path = data_path + csv_filename\n",
    "test_data_csv_path = test_data_path + csv_filename\n",
    "\n",
    "test_data_csv_df = pd.read_csv(test_data_csv_path, index_col=False)\n",
    "test_data_csv_df.columns = ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
    "\n",
    "data_test = test_data_csv_df.sample(n=len(test_data_csv_df))\n",
    "\n",
    "data_csv_df = pd.read_csv(data_csv_path, index_col=False)\n",
    "data_csv_df.columns = ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
    "data = data_csv_df.sample(n=len(data_csv_df))\n",
    "\n",
    "split_train = int(0.7*len(data))\n",
    "split_valid = int(0.9*len(data))\n",
    "split_test = len(data)\n",
    "\n",
    "data_train = data[:split_train]\n",
    "data_valid = data[split_train:split_valid]\n",
    "data_test = data[split_valid:split_test]\n",
    "\n",
    "print(len(data_train))\n",
    "print(len(data_valid))\n",
    "print(len(data_test))\n",
    "\n",
    "img_paths = data_train['center'][512:1024].values\n",
    "print(img_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "def read_img(path):\n",
    "    \"\"\"\n",
    "    Returns a numpy array image from path\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path.strip())\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_img(path):\n",
    "    image = Image.open(path)\n",
    "    image = image.convert('RGB')\n",
    "    return image\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Return processed data\n",
    "    \"\"\"\n",
    "    return data['center'], data['steering']\n",
    "    \n",
    "def images_to_nparray(image_list, w=160, h=320):\n",
    "    output = []\n",
    "    for image in image_list:\n",
    "        img = np.array(list(image.getdata()), dtype='uint8')\n",
    "        img = np.reshape(img, (w, h, 3))\n",
    "        output.append(img)\n",
    "    \n",
    "    return np.array(output, dtype='uint8')\n",
    "\n",
    "def get_batch(data, batch_size=512):\n",
    "    batch = data.sample(batch_size)\n",
    "    img_paths = batch['center'].values\n",
    "    steerings = batch['steering'].values\n",
    "    \n",
    "    img_list = []\n",
    "    for path in img_paths:\n",
    "        img = load_img(path)\n",
    "        img = np.asarray(img, dtype='float32')\n",
    "        img_list.append(img)\n",
    "    \n",
    "    imgs = np.array(img_list, dtype='float32')\n",
    "    strs = np.array(steerings, dtype='float32')\n",
    "    \n",
    "    return imgs, strs\n",
    "    \n",
    "    \n",
    "def train_sample_generator(train_df, batch_size=512):\n",
    "    \"\"\"\n",
    "    Generate a batch of training data\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        yield get_batch(train_df, batch_size=batch_size)\n",
    "        \n",
    "        \n",
    "def valid_sample_generator(valid_df, batch_size_valid=512):\n",
    "    return train_sample_generator(valid_df, batch_size_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.backend import tf as ktf\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def crop_imgs(imgs, top=60, bottom=140):\n",
    "    \"\"\"\n",
    "    Returns croppped image tensor\n",
    "    \"\"\"\n",
    "    return imgs[:,top:bottom,:,:]\n",
    "\n",
    "def nvidia_net(input_shape=(160, 320, 3)):    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # 160x320x3 -> 80x320x3\n",
    "    model.add(Lambda(crop_imgs, input_shape=input_shape))\n",
    "    \n",
    "    # 80x320x3 -> 80x320x3\n",
    "    model.add(Lambda(lambda x: x/255.-0.5))\n",
    "    \n",
    "    # -> 38x158x24\n",
    "    model.add(Conv2D(24, kernel_size=(5,5),\n",
    "                     strides=(2,2),\n",
    "                     activation='relu'))\n",
    "    \n",
    "    # -> 17x77x36\n",
    "    model.add(Conv2D(36, kernel_size=(5,5),\n",
    "                     strides=(2,2),\n",
    "                     activation=\"relu\"))\n",
    "    \n",
    "    # -> 7x37x48\n",
    "    model.add(Conv2D(48, kernel_size=(5, 5), \n",
    "                     strides=(2,2),\n",
    "                     activation=\"relu\"))\n",
    "    \n",
    "    # -> 3x18x64\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                     strides=(2,2),\n",
    "                     activation=\"relu\"))\n",
    "\n",
    "    # -> 1x16x64\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), \n",
    "                     activation=\"relu\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "58/58 [==============================] - 210s - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 2/5\n",
      "58/58 [==============================] - 210s - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 3/5\n",
      "58/58 [==============================] - 210s - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 4/5\n",
      "58/58 [==============================] - 211s - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 5/5\n",
      "57/58 [============================>.] - ETA: 3s - loss: 0.0038"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "BATCH_SIZE_VALID = 128\n",
    "EPOCHS = 5\n",
    "\n",
    "DATA_PATH = \"../sim_data/data/\"\n",
    "\n",
    "\n",
    "img = read_img(img_paths[0])\n",
    "input_shape = img.shape\n",
    "model = nvidia_net(input_shape)\n",
    "\n",
    "n_data_train = len(data_train)\n",
    "n_steps = int(n_data_train/BATCH_SIZE)\n",
    "\n",
    "n_data_valid = len(data_valid)\n",
    "n_steps_valid = int(n_data_valid/BATCH_SIZE_VALID)\n",
    "\n",
    "values = model.fit_generator(train_sample_generator(data_train, BATCH_SIZE),\n",
    "                             validation_data=valid_sample_generator(data_valid, BATCH_SIZE_VALID),\n",
    "                             steps_per_epoch=n_steps,\n",
    "                             validation_steps=n_steps_valid,\n",
    "                             epochs=EPOCHS)\n",
    "\n",
    "model.save('nvidia_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
